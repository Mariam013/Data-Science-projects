{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edab7bbf-04fb-404d-a8c7-b3d9dd21ba86",
   "metadata": {
    "cellUniqueIdByVincent": "6c82f"
   },
   "source": [
    "# Resources\n",
    "##### https://www.geeksforgeeks.org/downloading-files-web-using-python/\n",
    "##### https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "##### https://www.geeksforgeeks.org/beautifulsoup-scraping-paragraphs-from-html/\n",
    "##### https://www.geeksforgeeks.org/python-counter-objects-elements/\n",
    "##### https://www.geeksforgeeks.org/python-most_common-function/\n",
    "##### https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "##### https://scrapfly.io/blog/web-scraping-with-selenium-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e40033b4-154d-4530-9b17-486c402afdf6",
   "metadata": {
    "cellUniqueIdByVincent": "21b5e"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from urllib.parse import urlparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cdf7ed0-a54f-4d28-809e-cdc7e894d7d1",
   "metadata": {
    "cellUniqueIdByVincent": "78d0d"
   },
   "outputs": [],
   "source": [
    "class WebScraper:   \n",
    "    \"\"\"\n",
    "    This class contains multiple mthods that can be used for web scrapping of both static and dinamic websites.\n",
    "    It also supports keyword search\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url):  \n",
    "        self.url = url\n",
    "        self.filename = None\n",
    "        self.title = None\n",
    "        self.paragraphs = None\n",
    "        self.driver = None\n",
    "\n",
    "    def download_html(self, filename='webpage.html'):\n",
    "        \"\"\"\n",
    "        Downloads HTML content from the URL and saves it to a file.\n",
    "        Args:\n",
    "            filename (str): Name of the file to save HTML content (default: 'webpage.html')\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        r = requests.get(self.url)\n",
    "        r.raise_for_status()  # Check for HTTP errors\n",
    "        with open(self.filename, 'wb') as html:\n",
    "            html.write(r.content)\n",
    "       # return html\n",
    "    def extract_content(self):\n",
    "        \"\"\"\n",
    "        Extracts title and paragraphs from the downloaded HTML file.\n",
    "        Returns:\n",
    "            tuple: (title, paragraphs)\n",
    "        \"\"\"\n",
    "        with open(self.filename, 'r', encoding='utf-8') as html:\n",
    "            content = html.read()\n",
    "            parse_html = BeautifulSoup(content, 'html.parser')\n",
    "            self.title = parse_html.title.string if parse_html.title else None\n",
    "            self.paragraphs = [para.get_text() for para in parse_html.find_all(\"p\")]\n",
    "        return self.title, self.paragraphs\n",
    "\n",
    "    def save_text(self, filename='extracted_content.txt'): \n",
    "        \"\"\"\n",
    "        Saves extracted content to a text file.\n",
    "        Args:\n",
    "            filename (str): Name of the output file (default: 'extracted_content.txt')\n",
    "        \"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as file:  \n",
    "            if self.title:\n",
    "                file.write(f\"Title: {self.title}\\n\\n\")\n",
    "            for paragraph in self.paragraphs:\n",
    "                file.write(f\"\\n{paragraph}\\n\\n\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_multiple_pages(urls):\n",
    "        \"\"\"\n",
    "        Scrapes multiple web pages from a list of URLs and saves their content to separate files.\n",
    "        Args:\n",
    "            urls (list): A list of URLs to scrape.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for url in urls:\n",
    "            try:\n",
    "                file_name = url.split('.')[1]  # filename from URL\n",
    "                scraper = WebScraper(url)\n",
    "                \n",
    "                # Download and process content\n",
    "                scraper.download_html(f\"{file_name}.html\")\n",
    "                title, paragraphs = scraper.extract_content()\n",
    "                scraper.save_text(f\"{file_name}_content.txt\")\n",
    "                \n",
    "                results[url] = {\n",
    "                    'status': 'success',\n",
    "                    'html_file': f\"{file_name}.html\",\n",
    "                    'content_file': f\"{file_name}_content.txt\",\n",
    "                    'title': title\n",
    "                }\n",
    "                print(f\"Successfully processed: {url}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[url] = {\n",
    "                    'status': 'failed',\n",
    "                    'error': str(e)\n",
    "                }\n",
    "                print(f\"Failed to process: {url}\\nError: {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "    \n",
    "\n",
    "    def scrape_dynamic_content(self):\n",
    "        \"\"\"\n",
    "        Scrapes dynamic content using Selenium WebDriver.\n",
    "        user must have chrome or firefox drivers installed\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Configure Chrome options\n",
    "            options = Options()\n",
    "            options.headless = True \n",
    "            options.add_argument('--window-size=1920,1080')\n",
    "            options.add_argument('--no-sandbox')\n",
    "            options.add_argument('--disable-dev-shm-usage')\n",
    "            options.add_argument('--disable-gpu')\n",
    "            options.add_experimental_option(\n",
    "                \"prefs\", \n",
    "                {\"profile.managed_default_content_settings.images\": 2}\n",
    "            )\n",
    "            \n",
    "            # Initialize WebDriver\n",
    "            self.driver = webdriver.Chrome(options=options)\n",
    "            \n",
    "            # Navigate to URL\n",
    "            print(f\"Loading page: {self.url}\")\n",
    "            self.driver.get(self.url)\n",
    "            \n",
    "            # Wait for page to load\n",
    "            WebDriverWait(self.driver, timeout=10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div#mw-content-text')))\n",
    "\n",
    "            \n",
    "            # Get page content\n",
    "            page_content = self.driver.page_source\n",
    "            \n",
    "            # Generate filename from url\n",
    "            file_name = self.url.split('.')[1]\n",
    "            \n",
    "            # Save HTML content\n",
    "            html_file = f\"{file_name}_dynamic.html\"\n",
    "            with open(html_file, 'w', encoding='utf-8') as file:\n",
    "                file.write(page_content)\n",
    "            \n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'html_file': html_file,\n",
    "            }\n",
    "            \n",
    "        except TimeoutException as e:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'error': f\"Timeout waiting for elements: {str(e)}\"\n",
    "            }\n",
    "        except NoSuchElementException as e:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'error': f\"Element not found: {str(e)}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'error': f\"Error during scraping: {str(e)}\"\n",
    "            }\n",
    "        finally:\n",
    "            # close the driver\n",
    "            if self.driver:\n",
    "                self.driver.quit()\n",
    "                self.driver = None\n",
    "\n",
    "\n",
    "    def extract_metadata(self):\n",
    "        \"\"\"\n",
    "        Extracts meta description and keywords from the downloaded HTML file and saves to a file.\n",
    "        Args:\n",
    "        filename (str): Name of the file to save metadata (default: 'metadata.txt')\n",
    "        \"\"\"\n",
    "        with open(self.filename, 'r', encoding='utf-8') as html:\n",
    "            content = html.read()\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            \n",
    "            # Extract meta description and keywords\n",
    "            description = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "            keywords = soup.find(\"meta\", attrs={\"name\": \"keywords\"})\n",
    "            \n",
    "            # Get content attribute if meta tags are found\n",
    "            description_content = description[\"content\"] if description else \"No description found\"\n",
    "            keywords_content = keywords[\"content\"] if keywords else \"No keywords found\"\n",
    "        \n",
    "            # Save metadata to file\n",
    "            filename=\"metadata.txt\"\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(f\"URL: {self.url}\\n\")\n",
    "                file.write(f\"Title: {self.title}\\n\\n\")\n",
    "                file.write(f\"Meta Description: {description_content}\\n\\n\")\n",
    "                file.write(f\"Meta Keywords: {keywords_content}\\n\\n\")\n",
    "        \n",
    "        print(f\"Metadata extracted and saved to {filename}\")\n",
    "\n",
    "    def  keyword_search(self,keyword):\n",
    "        \"\"\"\n",
    "        Searches webpages for a keyword and returns the frequency of the keyword in each page.\n",
    "        Saves the count to a json file\n",
    "        Args:\n",
    "        keyword (str): keyword to search for \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Configure Chrome options\n",
    "            options = Options()\n",
    "            options.headless = True \n",
    "            options.add_argument('--window-size=1920,1080')\n",
    "            options.add_argument('--no-sandbox')\n",
    "            options.add_argument('--disable-dev-shm-usage')\n",
    "            options.add_argument('--disable-gpu')\n",
    "            options.add_experimental_option(\n",
    "                \"prefs\", \n",
    "                {\"profile.managed_default_content_settings.images\": 2}\n",
    "            )\n",
    "            \n",
    "            # Initialize WebDriver\n",
    "            self.driver = webdriver.Chrome(options=options)\n",
    "            \n",
    "            # Navigate to URL\n",
    "            print(f\"Loading page: {self.url}\")\n",
    "            self.driver.get(self.url)\n",
    "            \n",
    "            # Wait for page to load\n",
    "            WebDriverWait(self.driver, timeout=10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div#mw-content-text')))\n",
    "\n",
    "            \n",
    "             # Find and interact with the search box\n",
    "            search_box = self.driver.find_element(By.CSS_SELECTOR, 'input#searchInput')\n",
    "            search_box.clear()\n",
    "            search_box.send_keys(keyword)\n",
    "            search_box.send_keys(Keys.ENTER)  # Press Enter\n",
    "\n",
    "            # Scroll to load more items \n",
    "            keyword_counts = {}\n",
    "            page_number = 1\n",
    "            \n",
    "            while True:\n",
    "                print(\"Counting Keyword\")\n",
    "                # Scroll to load more items\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(5)  # Wait for additional content to load\n",
    "            \n",
    "                # Retrieve and parse page source\n",
    "                page_source = self.driver.page_source\n",
    "                soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "                # Extract text and perform case-insensitive keyword search\n",
    "                page_text = soup.get_text().lower()\n",
    "                keyword_lower = keyword.lower()\n",
    "                keyword_count = page_text.count(keyword_lower)#count keyword\n",
    "                \n",
    "                # Store count for this page number\n",
    "                keyword_counts[page_number] = keyword_count\n",
    "                print(f\"Page {page_number}: '{keyword}' found {keyword_count} times.\")\n",
    "            \n",
    "                # Check if additional content was loaded\n",
    "                if page_number > 1 and keyword_counts[page_number] == keyword_counts[page_number - 1]:\n",
    "                    break \n",
    "                page_number += 1\n",
    "            # Save the result to file\n",
    "            print(\"Preparing to save keyword counts...\")\n",
    "            with open(\"keyword_counts.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(keyword_counts, file, ensure_ascii=False, indent=4)\n",
    "            \n",
    "            print(\"Keyword counts saved to 'keyword_counts.json'\")\n",
    "            return keyword_counts\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during scraping: {str(e)}\")\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'error': f\"Error during scraping: {str(e)}\"\n",
    "            }\n",
    "        finally:\n",
    "            # close the driver\n",
    "            if self.driver:\n",
    "                self.driver.quit()\n",
    "                self.driver = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fada95a-55d7-4470-9604-ab57f3104377",
   "metadata": {
    "cellUniqueIdByVincent": "f64cd"
   },
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    \"\"\"\n",
    "    This class contain methods that cleans scaped data and extracts the needed content\n",
    "    It takes the file name as the arg.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_name):  \n",
    "        self.file_name = file_name\n",
    "\n",
    "    def clean_text(self, paragraphs):  \n",
    "        \"\"\"\n",
    "        Cleans and normalizes text from paragraphs.\n",
    "        Args:\n",
    "            paragraphs (list): List of paragraphs to clean\n",
    "        Returns:\n",
    "            list: Cleaned paragraphs\n",
    "        \"\"\"\n",
    "        cleaned_data = []\n",
    "        for para in paragraphs:\n",
    "            data = re.sub(r'[^\\w\\s]', '', para)  # Remove special characters\n",
    "            data = re.sub(r'\\s+', ' ', data).strip()  # Normalize whitespace\n",
    "            data = data.lower() #convert text to lowercase\n",
    "            cleaned_data.append(data)\n",
    "        return cleaned_data \n",
    "    @staticmethod\n",
    "    def aggregate_texts(file_names):\n",
    "        \"\"\"\n",
    "        Aggregates text content from multiple files and combines them into a single string.\n",
    "        Args:\n",
    "            file_names (list): List of filenames to read and aggregate content from.\n",
    "        Returns:\n",
    "            str: Combined content from all specified files.\n",
    "        \"\"\"\n",
    "        content = \"\"\n",
    "        for file_name in file_names:\n",
    "            with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                # Read the content of each file and add it to the aggregate\n",
    "                para = f.readlines()\n",
    "                content += \"\\n\".join(para) + '\\n'\n",
    "\n",
    "        with open('aggregated content.txt', 'w', encoding='utf-8') as new_file:  \n",
    "            #write the agrregated content to a new file\n",
    "            new_file.write(content)\n",
    "        return new_file\n",
    "\n",
    "    def find_frequent_words(self):\n",
    "        \"\"\"\n",
    "        Counts the occurance of each word from the aggregated file \n",
    "        \n",
    "        Returns:\n",
    "        first 10 most frequent words.\n",
    "        \"\"\"\n",
    "        with open(self.file_name, 'r', encoding='utf-8') as file:\n",
    "            content = file.read().lower()\n",
    "            # Tokenize the content into words\n",
    "            words = word_tokenize(content)\n",
    "            \n",
    "            # Filter out stopwords\n",
    "            filtered_words = [word for word in words if word.isalpha() and word not in stopwords.words('english')]\n",
    "            \n",
    "            # Count word frequencies\n",
    "            word_counts = Counter(filtered_words)\n",
    "            most_common_words = word_counts.most_common(10)\n",
    "        #Display top 10 words\n",
    "        counter = 0\n",
    "        print(f\"Top 10 most frequent words\")\n",
    "        for word, count in most_common_words:\n",
    "            counter += 1  \n",
    "            print(f\"{counter}. {word}: {count}\")\n",
    "        #return most_common_words\n",
    "                     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b93ee1d3-34a7-461f-85ab-49586168a068",
   "metadata": {
    "cellUniqueIdByVincent": "6bb13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://en.wikipedia.org/wiki/Web_scraping and saved it as webscrapingarticle.html\n",
      "content cleaned and saved as extracted_content.txt\n",
      "**************************************************\n",
      "Successfully processed: http://books.toscrape.com\n",
      "Successfully processed: http://books.toscrape.com\n",
      "Successfully processed: https://www.wikipedia.org\n",
      "Scraping completed for multiple pages.\n",
      "--------------------------------------------------\n",
      "Aggregation completed for multiple files.\n",
      "--------------------------------------------------\n",
      "Top 10 most frequent words\n",
      "1. stock: 40\n",
      "2. wikipedia: 7\n",
      "3. please: 4\n",
      "4. title: 3\n",
      "5. readers: 3\n",
      "6. read: 3\n",
      "7. give: 3\n",
      "8. reading: 3\n",
      "9. gift: 3\n",
      "10. every: 3\n",
      "**************************************************\n",
      "WEB SCRAPING USING SELENIUM \n",
      "\n",
      "Loading page: https://en.wikipedia.org/wiki/Web_scraping\n",
      "Scraping successful!\n",
      "HTML saved to: wikipedia_dynamic.html\n",
      "Metadata extracted and saved to metadata.txt\n",
      "Loading page: https://en.wikipedia.org/wiki/Web_scraping\n",
      "Counting Keyword\n",
      "Page 1: 'web' found 64 times.\n",
      "Counting Keyword\n",
      "Page 2: 'web' found 64 times.\n",
      "Preparing to save keyword counts...\n",
      "Keyword counts saved to 'keyword_counts.json'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = \"https://en.wikipedia.org/wiki/Web_scraping\"\n",
    "    file_name = \"webscrapingarticle.html\"\n",
    "    scraper = WebScraper(url)\n",
    "    scraper.download_html(file_name)\n",
    "    print(f\"Downloaded {url} and saved it as {file_name}\")\n",
    "    title, paragraphs = scraper.extract_content()\n",
    "  \n",
    "    save_file =\"extracted_content.txt\"\n",
    "    scraper.save_text(save_file)\n",
    "    tp = TextProcessor(save_file)\n",
    "    cleaned_paragraphs = tp.clean_text(paragraphs)\n",
    "    print(f\"content cleaned and saved as {save_file}\")\n",
    "    print('*' *50)\n",
    "\n",
    "    # List of URLs to scrape\n",
    "    urls = [\n",
    "        \"http://books.toscrape.com\",\n",
    "        \"http://books.toscrape.com\",\n",
    "        \"https://www.wikipedia.org\"\n",
    "    ]\n",
    "    \n",
    "    # Call scrape_multiple_pages with the list of URLs\n",
    "    WebScraper.scrape_multiple_pages(urls)\n",
    "    \n",
    "    print(\"Scraping completed for multiple pages.\")\n",
    "    print('-' *50)\n",
    "\n",
    "       # List of files to combine\n",
    "    file_names = [\n",
    "        \"toscrape_content.txt\",\n",
    "        \"toscrape_content.txt\",\n",
    "        \"wikipedia_content.txt\"\n",
    "    ]\n",
    "    \n",
    "    # Call scrape_multiple_pages with the list of URLs\n",
    "    TextProcessor.aggregate_texts(file_names)\n",
    "    print(\"Aggregation completed for multiple files.\")\n",
    "    print('-' *50)\n",
    "    \n",
    "    #find frequent words\n",
    "    analyzer = TextProcessor('aggregated content.txt')\n",
    "    analyzer.find_frequent_words()\n",
    "    print('*' *50)\n",
    "    print('WEB SCRAPING USING SELENIUM \\n')\n",
    "    #web scrapping using selenium\n",
    "    # Create scraper instance\n",
    "    #scraper = WebScraper(\"https://www.twitch.tv/directory/game/Art\")\n",
    "    \n",
    "    # Scrape dynamic content\n",
    "    result = scraper.scrape_dynamic_content()\n",
    "    \n",
    "    # Check results\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"Scraping successful!\")\n",
    "        print(f\"HTML saved to: {result['html_file']}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Scraping failed: {result['error']}\")\n",
    "\n",
    "\n",
    "    #Extracting metadata\n",
    "    scraper.download_html('wikipedia_dynamic.html')\n",
    "    scraper.extract_content()\n",
    "    scraper.extract_metadata()\n",
    "\n",
    "    #keyword counts\n",
    "    scraper.keyword_search('web')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e550f0bc-5fa7-48d3-8014-e144ba285530",
   "metadata": {
    "cellUniqueIdByVincent": "4f0c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity: 0.07602932978623586\n",
      "Sentiment subjectivity: 0.41428128041387724\n",
      "Number of positive: 26\n",
      "Number of negative: 10\n",
      "Number of neutral: 5\n",
      "Number of positive: 26\n",
      "Number of negative: 10\n",
      "Number of neutral: 5\n",
      "Sentiment Polarity: 0.07602932978623586\n",
      "Sentiment subjectivity: 0.41428128041387724\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SentimentAnalyzer:\n",
    "    \"\"\"\n",
    "    A class to analyze sentiment from text content and summarize the results.\n",
    "    \"\"\"\n",
    "\n",
    "    def analyze_sentiment(self, file_name=\"extracted_content.txt\"):\n",
    "        \"\"\"\n",
    "        Analyzes the sentiment of the text in the specified file.\n",
    "\n",
    "        Parameters:\n",
    "            file_name (str): The name of the file containing text to analyze. Defaults to 'extracted_content.txt'.\n",
    "        \"\"\"\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()  # Read the content of the file\n",
    "            blob = TextBlob(content)  # Create a TextBlob object for sentiment analysis\n",
    "            self.sentiment = blob.sentiment  # Get the sentiment of the content\n",
    "            self.polarity = self.sentiment.polarity  # Extract polarity from sentiment\n",
    "            self.subjectivity = self.sentiment.subjectivity  # Extract subjectivity from sentiment\n",
    "            \n",
    "            # Print sentiment results\n",
    "            print(f\"Sentiment Polarity: {self.sentiment.polarity}\")  # Measure positivity or negativity\n",
    "            print(f\"Sentiment subjectivity: {self.sentiment.subjectivity}\")  # Measure degree of opinion or objectivity\n",
    "\n",
    "    def count_sentiments(self, paragraphs):\n",
    "        \"\"\"\n",
    "        Counts the number of positive, negative, and neutral paragraphs.\n",
    "\n",
    "        Parameters:\n",
    "            paragraphs (list): A list of paragraphs to analyze.\n",
    "        \"\"\"\n",
    "        self.positive = 0  # Initialize positive count\n",
    "        self.negative = 0  # Initialize negative count\n",
    "        self.neutral = 0   # Initialize neutral count\n",
    "        self.total_paragraphs = len(paragraphs)  # Get total number of paragraphs\n",
    "\n",
    "        for para in paragraphs:\n",
    "            blob = TextBlob(para)  # Create a TextBlob object for each paragraph\n",
    "            sentiment = blob.sentiment.polarity  # Get the polarity of the paragraph\n",
    "            if sentiment > 0:\n",
    "                self.positive += 1  # Increment positive count\n",
    "            elif sentiment < 0:\n",
    "                self.negative += 1  # Increment negative count\n",
    "            else:\n",
    "                self.neutral += 1  # Increment neutral count\n",
    "\n",
    "        # Print counts of sentiments\n",
    "        print(f\"Number of positive: {self.positive}\")\n",
    "        print(f\"Number of negative: {self.negative}\")\n",
    "        print(f\"Number of neutral: {self.neutral}\")\n",
    "\n",
    "    def summarize_sentiment(self, paragraphs):\n",
    "        \"\"\"\n",
    "        Summarizes sentiment analysis results and writes to a file.\n",
    "\n",
    "        Parameters:\n",
    "            paragraphs (list): A list of paragraphs to analyze.\n",
    "        \"\"\"\n",
    "        self.count_sentiments(paragraphs)  # Count sentiments for the paragraphs\n",
    "        self.analyze_sentiment()  # Analyze sentiment for the entire text\n",
    "        \n",
    "        # Write the summary of the sentiment analysis to a file\n",
    "        with open(\"sentiment_summary.txt\", 'w') as file:\n",
    "            file.write(\"Sentiment Summary\\n\")  # Write header\n",
    "            file.write(f\"Total paragraphs: {self.total_paragraphs} \\n\")  # Write total paragraphs\n",
    "            file.write(f\"Number of positive: {self.positive}\\n\")  # Write positive count\n",
    "            file.write(f\"Number of negative: {self.negative}\\n\")  # Write negative count\n",
    "            file.write(f\"Number of neutral: {self.neutral} \\n\")  # Write neutral count\n",
    "            file.write(f\"Average sentiment polarity: {self.sentiment.polarity}\\n\")  # Write average polarity\n",
    "            file.write(f\"Average sentiment subjectivity: {self.sentiment.subjectivity}\\n\")  # Write average subjectivity\n",
    "\n",
    "# Initialize and run sentiment analysis\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "sentiment_analyzer.analyze_sentiment()  # Analyze sentiment of the content\n",
    "sentiment_analyzer.count_sentiments(cleaned_paragraphs)  # Count sentiments in cleaned paragraphs\n",
    "sentiment_analyzer.summarize_sentiment(cleaned_paragraphs)  # Summarize sentiments\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"\n",
    "    A class to visualize sentiment analysis results using bar plots.\n",
    "    \"\"\"\n",
    "\n",
    "    def plot_sentiment(self, counts):\n",
    "        \"\"\"\n",
    "        Plots the count of sentiments in a bar chart.\n",
    "\n",
    "        Parameters:\n",
    "            counts (list): A list containing counts of positive, negative, and neutral sentiments.\n",
    "        \"\"\"\n",
    "        sentiment = ['Positive', 'Negative', 'Neutral']  # Labels for the sentiment categories\n",
    "        plt.figure(figsize=(10, 5))  # Set figure size for the plot\n",
    "        plt.bar(sentiment, counts, color=['green', 'red', 'blue'])  # Create a bar chart with specified colors\n",
    "        plt.xlabel('Sentiment')  # Label for the x-axis\n",
    "        plt.ylabel('Count')  # Label for the y-axis\n",
    "        plt.title('Sentiment Analysis')  # Title of the plot\n",
    "        plt.show()  # Display the plot\n",
    "\n",
    "# Initialize and run visualization\n",
    "visualizer = Visualizer()\n",
    "visualizer.plot_sentiment([sentiment_analyzer.positive, sentiment_analyzer.negative, sentiment_analyzer.neutral])  # Plot sentiment counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f40013c1-d4dd-4231-80cb-cf5cc204d03e",
   "metadata": {
    "cellUniqueIdByVincent": "27095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis on aggregated content\n",
      "Sentiment Polarity: 0.16666666666666666\n",
      "Sentiment subjectivity: 0.6405555555555555\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment analysis on aggregated content\")\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "sentiment_analyzer.analyze_sentiment('aggregated content.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d2207-52c2-4a68-bce4-f88ca8aa371c",
   "metadata": {
    "cellUniqueIdByVincent": "37482"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "vincent": {
   "sessionId": "8ef82f0afa52e47e11d6b9e6_2025-04-10T05-25-29-815Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
